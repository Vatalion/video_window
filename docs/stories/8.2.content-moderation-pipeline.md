# Story 8.2: Content Moderation Pipeline

## Status
Ready for Dev

## Story
**As a** platform administrator,
**I want** published content to be automatically reviewed for compliance,
**so that** inappropriate content is prevented from reaching viewers

## Acceptance Criteria
1. **SECURITY CRITICAL**: All published stories go through automated moderation checks before appearing in feed, with zero bypass opportunities and audit logging of all moderation decisions.
2. **BUSINESS CRITICAL**: Stories flagged by moderation are held in pending_review status queue with automatic admin notifications and SLA tracking for review completion.
3. Admin can approve/reject stories in moderation queue with content preview, violation details, and structured feedback options for makers.
4. Makers receive real-time notifications when their story requires manual review, with estimated review timeline and actionable guidance.
5. Approved stories automatically transition to published status and appear in feed within 5 minutes of admin approval action.
6. Rejected stories include specific feedback for maker improvements with violation categories, suggested corrections, and resubmission guidance.

## Prerequisites
1. Story 8.1 – Publishing Workflow Implementation (publication trigger and status management)
2. Story 11.1 – Notification System (maker and admin notification infrastructure)
3. Epic 15 – Admin Moderation (admin panel and tooling - partial dependency)
4. AWS account with Rekognition or Sightengine API access configured

## Tasks / Subtasks

### Phase 1 – Automated Moderation Integration

- [ ] **SECURITY CRITICAL**: Implement video content scanning service (AC: 1) [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
  - [ ] Integrate AWS Rekognition or Sightengine video moderation API
  - [ ] Scan video frames for inappropriate visual content (violence, nudity, explicit content)
  - [ ] Configure moderation sensitivity thresholds per content category
  - [ ] Store moderation results with confidence scores in database
  - [ ] Generate video segments requiring human review when confidence < 90%
- [ ] Implement text content filtering (AC: 1) [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
  - [ ] Create `TextModerationService` with prohibited terms dictionary
  - [ ] Scan story overview, process timeline, and materials text fields
  - [ ] Apply context-aware filtering to reduce false positives
  - [ ] Flag stories containing profanity, hate speech, or prohibited content
  - [ ] Generate text violation reports with specific flagged segments
- [ ] Build image recognition for thumbnails and materials (AC: 1) [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
  - [ ] Use AWS Rekognition for image content moderation
  - [ ] Scan story thumbnail and all uploaded material images
  - [ ] Detect inappropriate imagery with category classification
  - [ ] Store image moderation results linked to specific assets
  - [ ] Auto-reject stories with high-confidence violations (>95%)

### Phase 2 – Moderation Queue System

- [ ] **BUSINESS CRITICAL**: Create moderation queue database schema (AC: 2) [Source: docs/tech-spec-epic-8.md – Moderation Queue]
  - [ ] Add `moderation_status` enum field to Story entity: pending_review, approved, rejected
  - [ ] Create `ModerationReview` table with story_id, flagged_at, reviewed_at, reviewer_id
  - [ ] Add `moderation_flags` JSONB field storing violation categories and confidence scores
  - [ ] Create `review_notes` text field for admin feedback to makers
  - [ ] Implement moderation_queue Redis sorted set for priority ordering
- [ ] Build admin review interface (AC: 3) [Source: docs/tech-spec-epic-8.md – Moderation Queue]
  - [ ] Create `ModerationQueuePage` in admin feature package
  - [ ] Display pending stories with violation summaries and priority ranking
  - [ ] Implement content preview with video playback and full metadata view
  - [ ] Show moderation flags with confidence scores and flagged segments
  - [ ] Add approve/reject actions with mandatory review notes for rejections
- [ ] Implement SLA tracking for moderation reviews (AC: 2) [Source: docs/tech-spec-epic-8.md – Moderation Queue]
  - [ ] Track time in queue with target SLA of 24 hours for review
  - [ ] Send admin alerts for stories exceeding SLA thresholds
  - [ ] Display queue metrics in admin dashboard (pending count, avg review time)
  - [ ] Prioritize flagged stories by violation severity and submission time

### Phase 3 – Notification & Feedback System

- [ ] Implement maker notification workflow (AC: 4) [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
  - [ ] Create `StoryUnderReviewNotification` event when moderation flags story
  - [ ] Include estimated review timeline (24-48 hours) and status tracking link
  - [ ] Send in-app notification and email with review guidance
  - [ ] Provide deep link to story status page showing review progress
- [ ] Build rejection feedback system (AC: 6) [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
  - [ ] Create `StoryRejectedNotification` with violation categories
  - [ ] Generate structured feedback with specific sections requiring correction
  - [ ] Provide resubmission guidance and policy documentation links
  - [ ] Allow makers to edit and resubmit rejected stories
  - [ ] Track resubmission attempts and moderation history
- [ ] Implement auto-approval workflow (AC: 5) [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
  - [ ] Transition approved stories from pending_review to published status
  - [ ] Trigger feed indexing via Redis queue (Story 8.1 integration)
  - [ ] Send `StoryApprovedNotification` to maker with go-live confirmation
  - [ ] Update moderation metrics and admin dashboard statistics
  - [ ] Log all status transitions with reviewer attribution for audit trail

## Dev Notes

### Previous Story Insights
- This is the second story in Epic 8, building on Story 8.1's publishing workflow. It adds a critical security layer before content reaches viewers. Story 8.3 will provide maker-facing approval status tracking.

### Data Models
- `Story` entity adds `moderation_status` enum, `moderation_flags` JSONB, and `review_notes` text field. [Source: docs/tech-spec-epic-8.md – Moderation Workflow]
- `ModerationReview` entity tracks review lifecycle: story_id, flagged_at, reviewed_at, reviewer_id, decision, notes. [Source: docs/tech-spec-epic-8.md – Moderation Queue]
- Moderation flags structure: `{ "video": { "violence": 0.85, "nudity": 0.12 }, "text": { "profanity": true }, "images": [] }`. [Source: docs/tech-spec-epic-8.md – Moderation Workflow]

### API Specifications
- `POST /moderation/review/{story_id}` accepts approve/reject decision with mandatory review_notes for rejections. [Source: docs/tech-spec-epic-8.md – Moderation Queue]
- `GET /moderation/queue` returns paginated pending stories with violation summaries and priority ranking.
- Third-party moderation APIs: AWS Rekognition for video/image, custom text filtering service for text content.
- Webhook integration for async moderation results from AWS Rekognition with retry/backoff handling.

### Component Specifications
- Moderation services in `video_window_flutter/packages/core/lib/services/moderation/` handle API integrations and result processing. [Source: docs/tech-spec-epic-8.md – Source Tree]
- Admin moderation UI in `video_window_flutter/packages/features/admin/` (Epic 15 partial implementation).
- Server moderation endpoints in `video_window_server/lib/src/endpoints/moderation/` manage queue and review workflows.
- Redis moderation queue with priority scoring: `moderation_queue` sorted set ordered by (severity_score * 1000) + submission_timestamp.
- Integration with notification system from Epic 11 for maker and admin alerts.
